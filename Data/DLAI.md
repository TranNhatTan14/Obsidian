---
aliases:
  - DeepLearning.AI
---
# Topics

- Agents
- AI Frameworks
- AI in Software Development
- AI Safety
- Anomaly Detection
- Chatbots
- Compression and Quantization
- Computer Vision
- Data Processing
- Deep Learning
- Diffusion Models
- Document Processing
- Embeddings
- Evaluation and Monitoring
- Event-Driven AI
- Fine-Tuning
- GenAI Applications
- Generative Models
- LLM Serving
- LLMOps
- Machine Learning
- MLOps
- MultiModal
- On-Device AI
- Prompt Engineering
- RAG
- Search and Retrieval
- Task Automation
- Transformers
- Vector Database
- Data Engineering
- Mathematical Foundations
- Supervised Learning
- Time Series
- Unsupervised Learning

# Courses

### ==Introducing Multimodal Llama 3.2==

Try out the features of the new Llama 3.2 models to build AI applications with multimodality.

### ==Retrieval Optimization: From Tokenization to Vector Quantization==

Build faster and more relevant vector search for your LLM applications

### ==Multimodal RAG: Chat with Videos==

Build an interactive system for querying video content using multimodal AI

### Large Multimodal Model Prompting with Gemini

Learn best practices for multimodal prompting using Googleâ€™s Gemini model.

### Building AI Applications with Haystack

Learn a flexible framework to build a variety of complex AI applications.

### Improving Accuracy of LLM Applications

Systematically improve the accuracy of LLM applications with evaluation, prompting, and memory tuning.

### Embedding Models: From Architecture to Implementation

Learn how to build embedding models and how to create effective semantic retrieval systems.

### Federated Learning

Build and fine-tune LLMs across distributed data using a federated learning framework for better privacy.

### ==Pretraining LLMs==

Learn the essential steps to pretrain a large language model from scratch.

### Prompt Compression and Query Optimization

Optimize the efficiency, security, query processing speed, and cost of your RAG applications.

### ==Function-Calling and Data Extraction with LLMs==

Learn to apply function-calling to expand LLM and agent application capabilities.

Nexusflow

### Building Your Own Database Agent

Interact with tabular data and SQL databases using natural language, enabling more efficient and accessible data analysis.

Microsoft

### AI Agents in LangGraph

Build agentic AI workflows using LangChain's LangGraph and Tavily's agentic search.

LangChain, Tavily

### AI Agentic Design Patterns with AutoGen

Use the AutoGen framework to build multi-agent systems with diverse roles and capabilities for implementing complex AI applications.

Microsoft, Penn State University

### Introduction to On-Device AI

Deploy AI for edge devices and smartphones. Learn model conversion, quantization, and how to modify for deployment on diverse devices.

Qualcomm

### Multi AI Agent Systems with crewAI

Automate business workflows with multi-AI agent systems. Exceed the performance of prompting a single LLM by designing and prompting a team of AI agents through natural language.

crewAI

### Building Multimodal Search and RAG

Build smarter search and RAG applications for multimodal retrieval and generation.

Weaviate

### Building Agentic RAG with LlamaIndex

Build autonomous agents that intelligently navigate and analyze your data. Learn to develop agentic RAG systems using LlamaIndex, enabling powerful document Q&A and summarization. Gain valuable skills in guiding agent reasoning and debugging.

LlamaIndex

### Quantization in Depth

Customize model compression with advanced quantization techniques. Try out different variants of Linear Quantization, including symmetric vs. asymmetric mode, and different granularities.

Hugging Face

### Prompt Engineering for Vision Models

Learn prompt engineering for vision models using Stable Diffusion, and advanced techniques like object detection and in-painting.

Comet

### Getting Started With Mistral

Explore Mistral's open-source and commercial models, and leverage Mistral's JSON mode to generate structured LLM responses. Use Mistral's API to call user-defined functions for enhanced LLM capabilities.

Mistral AI

### Quantization Fundamentals with Hugging Face

Learn how to quantize any open-source model. Learn to compress models with the Hugging Face Transformers library and the Quanto library.

Hugging Face

### Preprocessing Unstructured Data for LLM Applications

Improve your RAG system to retrieve diverse data types. Learn to extract and normalize content from a wide variety of document types, such as PDFs, PowerPoints, and HTML files.

Unstructured

### JavaScript RAG Web Apps with LlamaIndex

Build a full-stack web application that uses RAG capabilities to chat with your data. Learn to build a RAG application in JavaScript, using an intelligent agent to answer queries.


LlamaIndex
### Efficiently Serving LLMs

Understand how LLMs predict the next token and how techniques like KV caching can speed up text generation. Write code to serve LLM applications efficiently to multiple users.

Predibase

### Knowledge Graphs for RAG

Learn how to build and use knowledge graph systems to improve your retrieval augmented generation applications. Use Neo4j's query language Cypher to manage and retrieve data.

Neo4j

### Open Source Models with Hugging Face

Learn how to easily build AI applications using open-source models and Hugging Face tools. Find and filter open-source models on Hugging Face Hub.

Hugging Face

### Prompt Engineering with Llama 2 & 3

Learn best practices for prompting and selecting among Meta Llama 2 & 3 models. Interact with Meta Llama 2 Chat, Code Llama, and Llama Guard models.

Meta

### Serverless LLM apps with Amazon Bedrock

Learn how to deploy an LLM-based application into production using serverless technology. Learn to prompt and customize LLM responses with Amazon Bedrock.

AWS

### Building Applications with Vector Databases

Learn to build six applications powered by vector databases, including semantic search, retrieval augmented generation (RAG), and anomaly detection.

Pinecone

### Automated Testing for LLMOps

Learn how to create an automated CI pipeline to evaluate your LLM applications on every change, for faster and safer development.

CircleCI

### LLMOps

Learn LLMOps best practices as you design and automate steps to fine-tune and deploy an LLM for a specific task.

Google Cloud

### Build LLM Apps with LangChain.js

Expand your toolkit with LangChain.js, a JavaScript framework for building with LLMs. Understand the fundamentals of using LangChain to orchestrate and chain modules.

LangChain

### Advanced Retrieval for AI with Chroma

Learn advanced retrieval techniques to improve the relevancy of retrieved results. Learn to recognize poor query results and use LLMs to improve queries.

Chroma

### Reinforcement Learning from Human Feedback

Get an introduction to tuning and evaluating LLMs using Reinforcement Learning from Human Feedback (RLHF) and fine-tune the Llama 2 model.

Google Cloud

### Building and Evaluating Advanced RAG Applications

Learn advanced RAG retrieval methods like sentence-window and auto-merging that outperform baselines, and evaluate and iterate on your pipeline's performance.

TruEra, LlamaIndex

### Quality and Safety for LLM Applications

Learn how to evaluate the safety and security of your LLM applications and protect against risks. Monitor and enhance security measures to safeguard your apps.

WhyLabs

### Vector Databases: from Embeddings to Applications

Design and execute real-world applications of vector databases. Build efficient, practical applications, including hybrid and multilingual searches.

Weaviate

### Functions, Tools and Agents with LangChain

Learn about the latest advancements in LLM APIs and use LangChain Expression Language (LCEL) to compose and customize chains and agents.

LangChain

### Pair Programming with a Large Language Model

Learn how to prompt an LLM to help improve, debug, understand, and document your code. Use LLMs to simplify your code and enhance productivity.

Google

### Understanding and Applying Text Embeddings

Learn how to accelerate the application development process with text embeddings for sentence and paragraph meaning.

Google Cloud 

### ==Finetuning Large Language Models==

Discover when to use finetuning vs prompting for LLMs. Select suitable open-source models, prepare data, and train & evaluate for your specific domain.

Lamini

### Large Language Models with Semantic Search

Learn to use LLMs to enhance search and summarize results, using Cohere Rerank and embeddings for dense retrieval.

Cohere

### Evaluating and Debugging Generative AI Models Using Weights and Biases

Learn MLOps tools for managing, versioning, debugging, and experimenting in your ML workflow.

Weights & Biases

### Building Generative AI Applications with Gradio

Create and demo machine learning applications quickly. Share your app with teammates and beta testers on Hugging Face Spaces.

Hugging Face

### LangChain: Chat with Your Data

Create a chatbot with LangChain to interface with your private data and documents. Learn from LangChain creator, Harrison Chase.

LangChain

### How Diffusion Models Work

Learn and build diffusion models from the ground up, understanding each step. Learn about diffusion models in use today and implement algorithms to speed up sampling.

### LangChain for LLM Application Development

Use the powerful and extensible LangChain framework, using prompts, parsing, memory, chains, question answering, and agents.

LangChain

### Building Systems with the ChatGPT API

Learn to break down complex tasks, automate workflows, chain LLM calls, and get better outputs from LLMs. Evaluate LLM inputs and outputs for safety and relevance.

OpenAI

### ChatGPT Prompt Engineering for Developers

Learn the fundamentals of prompt engineering for ChatGPT. Learn effective prompting, and how to use LLMs for summarizing, inferring, transforming, and expanding.

OpenAI